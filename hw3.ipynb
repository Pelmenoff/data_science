{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNnjueq4PVpDzp8vV/ZBzwb"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import PolynomialFeatures, MinMaxScaler, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression, SGDRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "SEED = 17"
      ],
      "metadata": {
        "id": "EjI9CGpfsMkV"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/Housing.csv')\n",
        "\n",
        "X = df.drop('price', axis=1)\n",
        "y = df['price']\n",
        "\n",
        "X_encoded = pd.get_dummies(X, columns=['mainroad', 'guestroom', 'basement', 'hotwaterheating', 'airconditioning', 'prefarea', 'furnishingstatus'], drop_first=True)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=SEED)\n",
        "\n",
        "model = make_pipeline(\n",
        "    PolynomialFeatures(degree=2),\n",
        "    MinMaxScaler(),\n",
        "    LinearRegression()\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "predictions = model.predict(X_test)\n",
        "mse_sklearn = mean_squared_error(y_test, predictions)\n",
        "print(\"Mean Squared Error (MSE) with sklearn:\", mse_sklearn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZWqgaOTw4gi",
        "outputId": "89ad758a-1b2f-489c-8fa6-eb3ae856ec0e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error (MSE) with sklearn: 7329068550080376.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_sgd = make_pipeline(\n",
        "    PolynomialFeatures(degree=2),\n",
        "    MinMaxScaler(),\n",
        "    SGDRegressor(max_iter=1000, tol=1e-3, random_state=SEED)\n",
        ")\n",
        "\n",
        "model_sgd.fit(X_train, y_train)\n",
        "\n",
        "predictions_sgd = model_sgd.predict(X_test)\n",
        "mse_sgd = mean_squared_error(y_test, predictions_sgd)\n",
        "print(\"Mean Squared Error (MSE) with SGDRegressor:\", mse_sgd)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W05ddewaqt8v",
        "outputId": "31a2704d-28d0-4320-e586-0d7bb051bdc4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error (MSE) with SGDRegressor: 866127396611.2178\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def hypothesis(X, weights):\n",
        "    return X.dot(weights)\n",
        "\n",
        "def loss_function(X, y, weights):\n",
        "    predictions = hypothesis(X, weights)\n",
        "    errors = predictions - y\n",
        "    return np.mean(errors**2)\n",
        "\n",
        "def gradient_descent_step(X, y, weights, learning_rate):\n",
        "    predictions = hypothesis(X, weights)\n",
        "    errors = predictions - y\n",
        "    gradient = 2/X.shape[0] * X.T.dot(errors)\n",
        "    weights -= learning_rate * gradient\n",
        "    return weights\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "def gradient_descent_step_normalized(X, y, weights, learning_rate):\n",
        "    predictions = hypothesis(X, weights)\n",
        "    errors = predictions - y\n",
        "    gradient = 2/X.shape[0] * X.T.dot(errors)\n",
        "    weights -= learning_rate * gradient\n",
        "    return weights\n",
        "\n",
        "X_train_with_bias_scaled = np.c_[np.ones(X_train_scaled.shape[0]), X_train_scaled]\n",
        "weights_gradient_descent_scaled = np.zeros(X_train_with_bias_scaled.shape[1])\n",
        "\n",
        "learning_rate = 0.01\n",
        "for _ in range(1000):\n",
        "    weights_gradient_descent_scaled = gradient_descent_step_normalized(X_train_with_bias_scaled, y_train.values, weights_gradient_descent_scaled, learning_rate)\n",
        "\n",
        "print(\"gradient:\", weights_gradient_descent_scaled)\n",
        "\n",
        "X_train_with_bias = np.c_[np.ones(X_train.shape[0]), X_train]\n",
        "optimal_weights_analytical = np.linalg.inv(X_train_with_bias.T @ X_train_with_bias) @ X_train_with_bias.T @ y_train.values\n",
        "\n",
        "print(\"analitical:\", optimal_weights_analytical)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_cRmX9mp48R",
        "outputId": "2dc588ba-4170-45ee-ae65-021227e00559"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gradient: [ 4.82798508e+06  5.19809271e+05  1.28422745e+05  4.86154254e+05\n",
            "  3.69002732e+05  2.56722027e+05  1.58417177e+05  1.22338731e+05\n",
            "  1.51888494e+05  2.25642430e+05  4.52357359e+05  2.64278591e+05\n",
            " -1.27071664e+03 -1.93767697e+05]\n",
            "analitical: [-1.20758660e+05  2.39000824e+02  1.78219428e+05  9.79426744e+05\n",
            "  4.23734231e+05  2.95971521e+05  4.63103091e+05  3.08791097e+05\n",
            "  3.18291083e+05  1.05382503e+06  9.74460716e+05  6.16069287e+05\n",
            " -2.57226430e+03 -4.14210114e+05]\n"
          ]
        }
      ]
    }
  ]
}
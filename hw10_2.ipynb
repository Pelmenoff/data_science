{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pelmenoff/data_science/blob/main/hw10_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cDfeCHNEbave"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout, BatchNormalization, Input, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop, SGD, Nadam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kaDNXR-mbl1B",
        "outputId": "b544210e-be27-4d5e-8fb4-19eccbc57e5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n",
            "Train data size (42000, 28, 28)\n",
            "Test data size (12000, 28, 28)\n",
            "Validation data size (6000, 28, 28)\n"
          ]
        }
      ],
      "source": [
        "# Завантаження даних\n",
        "(x, y), _ = fashion_mnist.load_data()\n",
        "\n",
        "# Спочатку розділяємо дані на 70% тренувальні і 30% для тестування та валідації\n",
        "x_train, x_test_raw, y_train, y_test_raw = train_test_split(x, y, train_size=0.7, random_state=555)\n",
        "\n",
        "# Тепер розділимо ці 30% на 20% для тесту і 10% для валідації\n",
        "# 20% від загального числа = 20/30 частини від x_test_raw та y_test_raw\n",
        "test_size = 20 / 30\n",
        "x_val, x_test, y_val, y_test = train_test_split(x_test_raw, y_test_raw, test_size=test_size, random_state=555)\n",
        "\n",
        "print(\"Train data size\", x_train.shape)\n",
        "print(\"Test data size\", x_test.shape)\n",
        "print(\"Validation data size\", x_val.shape)\n",
        "\n",
        "# Масштабування зображень до діапазону [0, 1]\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_val = x_val.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "# Розширення розмірності (додавання каналу)\n",
        "x_train = np.expand_dims(x_train, -1)\n",
        "x_val = np.expand_dims(x_val, -1)\n",
        "x_test = np.expand_dims(x_test, -1)\n",
        "\n",
        "# One-hot кодування міток\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_val = to_categorical(y_val, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# Зміна розміру зображень до 32x32 для використання з VGG16\n",
        "x_train = tf.image.resize(x_train, (32, 32))\n",
        "x_val = tf.image.resize(x_val, (32, 32))\n",
        "x_test = tf.image.resize(x_test, (32, 32))\n",
        "\n",
        "# Перетворення на трьохканальні зображення\n",
        "x_train = tf.image.grayscale_to_rgb(x_train)\n",
        "x_val = tf.image.grayscale_to_rgb(x_val)\n",
        "x_test = tf.image.grayscale_to_rgb(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhdy_jJOb9cb",
        "outputId": "17770f70-f4aa-46f7-def0-72190e07ed97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Завантажити модель VGG16 без верхніх шарів\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_tensor=Input(shape=(32, 32, 3)))\n",
        "base_model.trainable = False\n",
        "\n",
        "# Розморозити верхні шари VGG16\n",
        "for layer in base_model.layers[-4:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "# Побудова моделі\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dense(256, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dense(64, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dense(10, activation='softmax'),\n",
        "])\n",
        "\n",
        "# Компільовання моделі\n",
        "model.compile(optimizer=Nadam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KH5k8b26bZcN"
      },
      "outputs": [],
      "source": [
        "# Використання Callback-функцій\n",
        "callbacks = [\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1),\n",
        "    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3o6nXBZ4sAgZ",
        "outputId": "1da1ba4f-388b-462e-8460-f1eba4b305f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vgg16 (Functional)          (None, 1, 1, 512)         14714688  \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               262656    \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 512)               2048      \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 256)               1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                16448     \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 64)                256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 15129098 (57.71 MB)\n",
            "Trainable params: 412746 (1.57 MB)\n",
            "Non-trainable params: 14716352 (56.14 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZvoSO-LcF1H",
        "outputId": "2a27b526-f5bb-4a01-ed65-b83803cb161c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1312/1312 [==============================] - 552s 417ms/step - loss: 0.6717 - accuracy: 0.7748 - val_loss: 0.4651 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
            "Epoch 2/20\n",
            "1312/1312 [==============================] - 516s 393ms/step - loss: 0.4463 - accuracy: 0.8434 - val_loss: 0.4036 - val_accuracy: 0.8547 - lr: 1.0000e-04\n",
            "Epoch 3/20\n",
            "1312/1312 [==============================] - 541s 412ms/step - loss: 0.3949 - accuracy: 0.8597 - val_loss: 0.3830 - val_accuracy: 0.8642 - lr: 1.0000e-04\n",
            "Epoch 4/20\n",
            "1312/1312 [==============================] - 541s 412ms/step - loss: 0.3561 - accuracy: 0.8725 - val_loss: 0.3813 - val_accuracy: 0.8635 - lr: 1.0000e-04\n",
            "Epoch 5/20\n",
            "1312/1312 [==============================] - 539s 411ms/step - loss: 0.3282 - accuracy: 0.8802 - val_loss: 0.3613 - val_accuracy: 0.8672 - lr: 1.0000e-04\n",
            "Epoch 6/20\n",
            "1312/1312 [==============================] - 536s 409ms/step - loss: 0.3063 - accuracy: 0.8897 - val_loss: 0.3596 - val_accuracy: 0.8698 - lr: 1.0000e-04\n",
            "Epoch 7/20\n",
            "1312/1312 [==============================] - 535s 408ms/step - loss: 0.2866 - accuracy: 0.8962 - val_loss: 0.3671 - val_accuracy: 0.8678 - lr: 1.0000e-04\n",
            "Epoch 8/20\n",
            "1312/1312 [==============================] - 519s 396ms/step - loss: 0.2694 - accuracy: 0.9009 - val_loss: 0.3644 - val_accuracy: 0.8730 - lr: 1.0000e-04\n",
            "Epoch 9/20\n",
            "1312/1312 [==============================] - ETA: 0s - loss: 0.2564 - accuracy: 0.9069\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "1312/1312 [==============================] - 537s 409ms/step - loss: 0.2564 - accuracy: 0.9069 - val_loss: 0.3646 - val_accuracy: 0.8715 - lr: 1.0000e-04\n",
            "Epoch 10/20\n",
            "1312/1312 [==============================] - 532s 406ms/step - loss: 0.2196 - accuracy: 0.9214 - val_loss: 0.3494 - val_accuracy: 0.8752 - lr: 5.0000e-05\n",
            "Epoch 11/20\n",
            "1312/1312 [==============================] - 517s 394ms/step - loss: 0.2064 - accuracy: 0.9257 - val_loss: 0.3464 - val_accuracy: 0.8787 - lr: 5.0000e-05\n",
            "Epoch 12/20\n",
            "1312/1312 [==============================] - 535s 408ms/step - loss: 0.1958 - accuracy: 0.9314 - val_loss: 0.3454 - val_accuracy: 0.8830 - lr: 5.0000e-05\n",
            "Epoch 13/20\n",
            "1312/1312 [==============================] - 542s 413ms/step - loss: 0.1873 - accuracy: 0.9337 - val_loss: 0.3556 - val_accuracy: 0.8763 - lr: 5.0000e-05\n",
            "Epoch 14/20\n",
            "1312/1312 [==============================] - 542s 413ms/step - loss: 0.1795 - accuracy: 0.9361 - val_loss: 0.3576 - val_accuracy: 0.8787 - lr: 5.0000e-05\n",
            "Epoch 15/20\n",
            "1312/1312 [==============================] - ETA: 0s - loss: 0.1722 - accuracy: 0.9393\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
            "1312/1312 [==============================] - 542s 413ms/step - loss: 0.1722 - accuracy: 0.9393 - val_loss: 0.3586 - val_accuracy: 0.8792 - lr: 5.0000e-05\n",
            "Epoch 16/20\n",
            "1312/1312 [==============================] - 523s 398ms/step - loss: 0.1528 - accuracy: 0.9482 - val_loss: 0.3527 - val_accuracy: 0.8837 - lr: 2.5000e-05\n",
            "Epoch 17/20\n",
            "1312/1312 [==============================] - 547s 417ms/step - loss: 0.1461 - accuracy: 0.9509 - val_loss: 0.3557 - val_accuracy: 0.8842 - lr: 2.5000e-05\n",
            "Epoch 18/20\n",
            "1312/1312 [==============================] - ETA: 0s - loss: 0.1406 - accuracy: 0.9536\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
            "1312/1312 [==============================] - 547s 417ms/step - loss: 0.1406 - accuracy: 0.9536 - val_loss: 0.3552 - val_accuracy: 0.8863 - lr: 2.5000e-05\n",
            "Epoch 19/20\n",
            "1312/1312 [==============================] - 546s 416ms/step - loss: 0.1313 - accuracy: 0.9564 - val_loss: 0.3594 - val_accuracy: 0.8838 - lr: 1.2500e-05\n",
            "Epoch 20/20\n",
            "1312/1312 [==============================] - 541s 412ms/step - loss: 0.1288 - accuracy: 0.9580 - val_loss: 0.3600 - val_accuracy: 0.8860 - lr: 1.2500e-05\n"
          ]
        }
      ],
      "source": [
        "# Навчання моделі\n",
        "batch_size = 32\n",
        "epochs = 20\n",
        "\n",
        "history = model.fit(x_train, y_train, batch_size=batch_size,\n",
        "    validation_data=(x_val, y_val),\n",
        "    steps_per_epoch=len(x_train) // batch_size,\n",
        "    epochs=epochs,\n",
        "    callbacks=callbacks\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "GrzYK2v8cHnk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab0862a5-2ad0-4311-ad99-d822e4c2501c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.37660250067710876\n",
            "Test accuracy: 0.8803333044052124\n"
          ]
        }
      ],
      "source": [
        "# Оцінка моделі\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(f'Test loss: {score[0]}')\n",
        "print(f'Test accuracy: {score[1]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Багатошарова модель з завдання 1 працює краще."
      ],
      "metadata": {
        "id": "304M_dQv6Y5S"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN+nzV6cHUQOqvRb/QHXFnA",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}